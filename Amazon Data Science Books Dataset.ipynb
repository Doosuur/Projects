{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b77404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56ea1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price</th>\n",
       "      <th>price (including used books)</th>\n",
       "      <th>pages</th>\n",
       "      <th>avg_reviews</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>weight</th>\n",
       "      <th>language</th>\n",
       "      <th>publisher</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>link</th>\n",
       "      <th>complete_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analysis Using R (Low Priced Edition): A ...</td>\n",
       "      <td>[ Dr Dhaval Maheta]</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>500</td>\n",
       "      <td>4.4</td>\n",
       "      <td>23</td>\n",
       "      <td>55%</td>\n",
       "      <td>39%</td>\n",
       "      <td>6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5 x 1.01 x 11 inches</td>\n",
       "      <td>2.53 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Notion Press Media Pvt Ltd (November 22, 2021)</td>\n",
       "      <td>978-1685549596</td>\n",
       "      <td>/Data-Analysis-Using-Low-Priced/dp/1685549594/...</td>\n",
       "      <td>https://www.amazon.com/Data-Analysis-Using-Low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Head First Data Analysis: A learner's guide to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.72</td>\n",
       "      <td>21.49 - 33.72</td>\n",
       "      <td>484</td>\n",
       "      <td>4.3</td>\n",
       "      <td>124</td>\n",
       "      <td>61%</td>\n",
       "      <td>20%</td>\n",
       "      <td>9%</td>\n",
       "      <td>4%</td>\n",
       "      <td>6%</td>\n",
       "      <td>8 x 0.98 x 9.25 inches</td>\n",
       "      <td>1.96 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 1st edition (August 18, 2009)</td>\n",
       "      <td>978-0596153939</td>\n",
       "      <td>/Head-First-Data-Analysis-statistics/dp/059615...</td>\n",
       "      <td>https://www.amazon.com/Head-First-Data-Analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guerrilla Data Analysis Using Microsoft Excel:...</td>\n",
       "      <td>[ Oz du Soleil,  and , Bill Jelen]</td>\n",
       "      <td>32.07</td>\n",
       "      <td>32.07</td>\n",
       "      <td>274</td>\n",
       "      <td>4.7</td>\n",
       "      <td>10</td>\n",
       "      <td>87%</td>\n",
       "      <td>13%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.25 x 0.6 x 10.75 inches</td>\n",
       "      <td>1.4 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Holy Macro! Books; Third edition (August 1, 2022)</td>\n",
       "      <td>978-1615470747</td>\n",
       "      <td>/Guerrilla-Analysis-Using-Microsoft-Excel/dp/1...</td>\n",
       "      <td>https://www.amazon.com/Guerrilla-Analysis-Usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python for Data Analysis: Data Wrangling with ...</td>\n",
       "      <td>[ William McKinney]</td>\n",
       "      <td>53.99</td>\n",
       "      <td>53.99</td>\n",
       "      <td>547</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1,686</td>\n",
       "      <td>75%</td>\n",
       "      <td>16%</td>\n",
       "      <td>5%</td>\n",
       "      <td>2%</td>\n",
       "      <td>2%</td>\n",
       "      <td>7 x 1.11 x 9.19 inches</td>\n",
       "      <td>1.47 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 2nd edition (November 14, 2017)</td>\n",
       "      <td>978-1491957660</td>\n",
       "      <td>/Python-Data-Analysis-Wrangling-IPython/dp/149...</td>\n",
       "      <td>https://www.amazon.com/Python-Data-Analysis-Wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excel Data Analysis For Dummies (For Dummies (...</td>\n",
       "      <td>[ Paul McFedries]</td>\n",
       "      <td>24.49</td>\n",
       "      <td>24.49</td>\n",
       "      <td>368</td>\n",
       "      <td>3.9</td>\n",
       "      <td>12</td>\n",
       "      <td>52%</td>\n",
       "      <td>17%</td>\n",
       "      <td>10%</td>\n",
       "      <td>10%</td>\n",
       "      <td>10%</td>\n",
       "      <td>7.38 x 0.83 x 9.25 inches</td>\n",
       "      <td>1.3 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>For Dummies; 5th edition (February 3, 2022)</td>\n",
       "      <td>978-1119844426</td>\n",
       "      <td>/Excel-Data-Analysis-Dummies-Computer/dp/11198...</td>\n",
       "      <td>https://www.amazon.com/Excel-Data-Analysis-Dum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Everything Data Analytics: A Beginner's Guide ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2</td>\n",
       "      <td>31</td>\n",
       "      <td>61%</td>\n",
       "      <td>16%</td>\n",
       "      <td>14%</td>\n",
       "      <td>4%</td>\n",
       "      <td>5%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Everything-Data-Analytics-Beginners-Understan...</td>\n",
       "      <td>https://www.amazon.com/Everything-Data-Analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SQL for Data Analysis: Advanced Techniques for...</td>\n",
       "      <td>[ Cathy Tanimura]</td>\n",
       "      <td>40.49</td>\n",
       "      <td>40.49</td>\n",
       "      <td>360</td>\n",
       "      <td>4.6</td>\n",
       "      <td>72</td>\n",
       "      <td>75%</td>\n",
       "      <td>18%</td>\n",
       "      <td>2%</td>\n",
       "      <td>2%</td>\n",
       "      <td>2%</td>\n",
       "      <td>6.75 x 0.75 x 8.75 inches</td>\n",
       "      <td>1.2 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 1st edition (October 5, 2021)</td>\n",
       "      <td>978-1492088783</td>\n",
       "      <td>/SQL-Data-Analysis-Techniques-Transforming/dp/...</td>\n",
       "      <td>https://www.amazon.com/SQL-Data-Analysis-Techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qualitative Data Analysis: A Methods Sourcebook</td>\n",
       "      <td>[ Matthew B. Miles, A. Michael Huberman, et al.]</td>\n",
       "      <td>90.00</td>\n",
       "      <td>90</td>\n",
       "      <td>408</td>\n",
       "      <td>4.7</td>\n",
       "      <td>205</td>\n",
       "      <td>84%</td>\n",
       "      <td>9%</td>\n",
       "      <td>4%</td>\n",
       "      <td>2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5 x 0.92 x 11 inches</td>\n",
       "      <td>2.15 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>SAGE Publications, Inc; 4th edition (January 2...</td>\n",
       "      <td>Research in Drama Education</td>\n",
       "      <td>/Qualitative-Data-Analysis-Methods-Sourcebook/...</td>\n",
       "      <td>https://www.amazon.com/Qualitative-Data-Analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Topological Data Analysis with Applications</td>\n",
       "      <td>[ Gunnar Carlsson,  and , Mikael Vejdemo-Johan...</td>\n",
       "      <td>54.19</td>\n",
       "      <td>53.98 - 54.19</td>\n",
       "      <td>230</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75 x 0.75 x 9.75 inches</td>\n",
       "      <td>1.28 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Cambridge University Press; 1st edition (March...</td>\n",
       "      <td>978-1108838658</td>\n",
       "      <td>/Topological-Analysis-Applications-Gunnar-Carl...</td>\n",
       "      <td>https://www.amazon.com/Topological-Analysis-Ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R in Action, Third Edition: Data analysis and ...</td>\n",
       "      <td>[ Robert I. Kabacoff]</td>\n",
       "      <td>56.99</td>\n",
       "      <td>47.97 - 56.99</td>\n",
       "      <td>656</td>\n",
       "      <td>4.3</td>\n",
       "      <td>14</td>\n",
       "      <td>78%</td>\n",
       "      <td>11%</td>\n",
       "      <td>11%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.38 x 1.5 x 9.25 inches</td>\n",
       "      <td>2.62 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Manning; 3rd edition (May 3, 2022)</td>\n",
       "      <td>978-1617296055</td>\n",
       "      <td>/Action-Third-Robert-I-Kabacoff/dp/1617296058/...</td>\n",
       "      <td>https://www.amazon.com/Action-Third-Robert-I-K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Listening to People: A Practical Guide to Inte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20</td>\n",
       "      <td>333</td>\n",
       "      <td>4.5</td>\n",
       "      <td>46</td>\n",
       "      <td>73%</td>\n",
       "      <td>13%</td>\n",
       "      <td>7%</td>\n",
       "      <td>3%</td>\n",
       "      <td>3%</td>\n",
       "      <td>6 x 0.9 x 9 inches</td>\n",
       "      <td>1.01 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>University of Chicago Press (October 15, 2021)</td>\n",
       "      <td>978-0226806433</td>\n",
       "      <td>/Listening-People-Interviewing-Participant-Obs...</td>\n",
       "      <td>https://www.amazon.com/Listening-People-Interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SQL for Data Analytics: Perform efficient and ...</td>\n",
       "      <td>[ Chad Knowles]</td>\n",
       "      <td>15.97</td>\n",
       "      <td>15.97</td>\n",
       "      <td>106</td>\n",
       "      <td>4.9</td>\n",
       "      <td>201</td>\n",
       "      <td>91%</td>\n",
       "      <td>8%</td>\n",
       "      <td>1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 x 0.24 x 9 inches</td>\n",
       "      <td>7.5 ounces</td>\n",
       "      <td>English</td>\n",
       "      <td>Independently published (September 21, 2022)</td>\n",
       "      <td>979-8354008353</td>\n",
       "      <td>/gp/slredirect/picassoRedirect.html/ref=pa_sp_...</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Python for Beginners: 2 Books in 1: The Perfec...</td>\n",
       "      <td>[ Programming Languages Academy, Matthew Kinse...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>292</td>\n",
       "      <td>63%</td>\n",
       "      <td>22%</td>\n",
       "      <td>7%</td>\n",
       "      <td>3%</td>\n",
       "      <td>4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Python-Beginners-Perfect-Learning-Workbook/dp...</td>\n",
       "      <td>https://www.amazon.com/Python-Beginners-Perfec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analytics, Data Visualization &amp; Communica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.60</td>\n",
       "      <td>28.6</td>\n",
       "      <td>528</td>\n",
       "      <td>4.6</td>\n",
       "      <td>20</td>\n",
       "      <td>81%</td>\n",
       "      <td>11%</td>\n",
       "      <td>7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 x 1.19 x 9 inches</td>\n",
       "      <td>1.93 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Kenneth M Fornari (November 10, 2022)</td>\n",
       "      <td></td>\n",
       "      <td>/gp/slredirect/picassoRedirect.html/ref=pa_sp_...</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Getting Started with Natural Language Processing</td>\n",
       "      <td>[ Ekaterina Kochmar]</td>\n",
       "      <td>39.99</td>\n",
       "      <td>39.99</td>\n",
       "      <td>456</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>48%</td>\n",
       "      <td>52%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.38 x 1.1 x 9.25 inches</td>\n",
       "      <td>1.75 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Manning (October 18, 2022)</td>\n",
       "      <td></td>\n",
       "      <td>/Getting-Started-Natural-Language-Processing/d...</td>\n",
       "      <td>https://www.amazon.com/Getting-Started-Natural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SQL QuickStart Guide: The Simplified Beginner'...</td>\n",
       "      <td>[ Walter Shields]</td>\n",
       "      <td>24.99</td>\n",
       "      <td>24.99</td>\n",
       "      <td>249</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1,358</td>\n",
       "      <td>72%</td>\n",
       "      <td>18%</td>\n",
       "      <td>7%</td>\n",
       "      <td>1%</td>\n",
       "      <td>2%</td>\n",
       "      <td>7.5 x 0.57 x 9.25 inches</td>\n",
       "      <td>15.5 ounces</td>\n",
       "      <td>English</td>\n",
       "      <td>ClydeBank Media LLC; Illustrated edition (Nove...</td>\n",
       "      <td>978-1945051753</td>\n",
       "      <td>/gp/slredirect/picassoRedirect.html/ref=pa_sp_...</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Monty Python And The Holy Grail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Monty-Python-Grail-Graham-Chapman/dp/B07PGCJM...</td>\n",
       "      <td>https://www.amazon.com/Monty-Python-Grail-Grah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Python in easy steps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.69</td>\n",
       "      <td>10.69</td>\n",
       "      <td>192</td>\n",
       "      <td>4.6</td>\n",
       "      <td>386</td>\n",
       "      <td>74%</td>\n",
       "      <td>14%</td>\n",
       "      <td>8%</td>\n",
       "      <td>2%</td>\n",
       "      <td>2%</td>\n",
       "      <td>7.25 x 0.5 x 9 inches</td>\n",
       "      <td>15.2 ounces</td>\n",
       "      <td>English</td>\n",
       "      <td>In Easy Steps Limited; 2nd edition (August 28,...</td>\n",
       "      <td>978-1840788129</td>\n",
       "      <td>/Python-easy-steps-Covers-3-7/dp/1840788127/re...</td>\n",
       "      <td>https://www.amazon.com/Python-easy-steps-Cover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Python para Principiantes: 2 Libros en 1: Prog...</td>\n",
       "      <td>[ Programming Languages Academy]</td>\n",
       "      <td>19.38</td>\n",
       "      <td>19.38</td>\n",
       "      <td>234</td>\n",
       "      <td>4.4</td>\n",
       "      <td>56</td>\n",
       "      <td>73%</td>\n",
       "      <td>8%</td>\n",
       "      <td>10%</td>\n",
       "      <td>4%</td>\n",
       "      <td>4%</td>\n",
       "      <td>6 x 0.53 x 9 inches</td>\n",
       "      <td>11.4 ounces</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Independently published (May 2, 2020)</td>\n",
       "      <td>979-8642649534</td>\n",
       "      <td>/Python-para-Principiantes-Programaci%C3%B3n-p...</td>\n",
       "      <td>https://www.amazon.com/Python-para-Principiant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Quantum Machine Learning and Optimisation in F...</td>\n",
       "      <td>[ Antoine Jacquier, Oleksiy Kondratyev, et al.]</td>\n",
       "      <td>49.99</td>\n",
       "      <td>36.00 - 49.99</td>\n",
       "      <td>442</td>\n",
       "      <td>4.9</td>\n",
       "      <td>14</td>\n",
       "      <td>90%</td>\n",
       "      <td>10%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5 x 1 x 9.25 inches</td>\n",
       "      <td>1.67 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Packt Publishing (October 31, 2022)</td>\n",
       "      <td></td>\n",
       "      <td>/gp/slredirect/picassoRedirect.html/ref=pa_sp_...</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Data Analysis Using R (Low Priced Edition): A ...   \n",
       "1   Head First Data Analysis: A learner's guide to...   \n",
       "2   Guerrilla Data Analysis Using Microsoft Excel:...   \n",
       "3   Python for Data Analysis: Data Wrangling with ...   \n",
       "4   Excel Data Analysis For Dummies (For Dummies (...   \n",
       "5   Everything Data Analytics: A Beginner's Guide ...   \n",
       "6   SQL for Data Analysis: Advanced Techniques for...   \n",
       "7     Qualitative Data Analysis: A Methods Sourcebook   \n",
       "8         Topological Data Analysis with Applications   \n",
       "9   R in Action, Third Edition: Data analysis and ...   \n",
       "10  Listening to People: A Practical Guide to Inte...   \n",
       "11  SQL for Data Analytics: Perform efficient and ...   \n",
       "12  Python for Beginners: 2 Books in 1: The Perfec...   \n",
       "13  Data Analytics, Data Visualization & Communica...   \n",
       "14   Getting Started with Natural Language Processing   \n",
       "15  SQL QuickStart Guide: The Simplified Beginner'...   \n",
       "16                    Monty Python And The Holy Grail   \n",
       "17                               Python in easy steps   \n",
       "18  Python para Principiantes: 2 Libros en 1: Prog...   \n",
       "19  Quantum Machine Learning and Optimisation in F...   \n",
       "\n",
       "                                               author  price  \\\n",
       "0                                 [ Dr Dhaval Maheta]   6.75   \n",
       "1                                                 NaN  33.72   \n",
       "2                  [ Oz du Soleil,  and , Bill Jelen]  32.07   \n",
       "3                                 [ William McKinney]  53.99   \n",
       "4                                   [ Paul McFedries]  24.49   \n",
       "5                                                 NaN    NaN   \n",
       "6                                   [ Cathy Tanimura]  40.49   \n",
       "7    [ Matthew B. Miles, A. Michael Huberman, et al.]  90.00   \n",
       "8   [ Gunnar Carlsson,  and , Mikael Vejdemo-Johan...  54.19   \n",
       "9                               [ Robert I. Kabacoff]  56.99   \n",
       "10                                                NaN  20.00   \n",
       "11                                    [ Chad Knowles]  15.97   \n",
       "12  [ Programming Languages Academy, Matthew Kinse...    NaN   \n",
       "13                                                NaN  28.60   \n",
       "14                               [ Ekaterina Kochmar]  39.99   \n",
       "15                                  [ Walter Shields]  24.99   \n",
       "16                                                NaN    NaN   \n",
       "17                                                NaN  10.69   \n",
       "18                   [ Programming Languages Academy]  19.38   \n",
       "19    [ Antoine Jacquier, Oleksiy Kondratyev, et al.]  49.99   \n",
       "\n",
       "   price (including used books) pages  avg_reviews n_reviews star5 star4  \\\n",
       "0                          6.75   500          4.4        23   55%   39%   \n",
       "1                21.49 - 33.72    484          4.3       124   61%   20%   \n",
       "2                         32.07   274          4.7        10   87%   13%   \n",
       "3                         53.99   547          4.6     1,686   75%   16%   \n",
       "4                         24.49   368          3.9        12   52%   17%   \n",
       "5                           NaN   NaN          4.2        31   61%   16%   \n",
       "6                         40.49   360          4.6        72   75%   18%   \n",
       "7                            90   408          4.7       205   84%    9%   \n",
       "8                53.98 - 54.19    230          5.0         5  100%   NaN   \n",
       "9                47.97 - 56.99    656          4.3        14   78%   11%   \n",
       "10                           20   333          4.5        46   73%   13%   \n",
       "11                        15.97   106          4.9       201   91%    8%   \n",
       "12                          NaN   NaN          4.4       292   63%   22%   \n",
       "13                         28.6   528          4.6        20   81%   11%   \n",
       "14                        39.99   456          4.0         4   48%   52%   \n",
       "15                        24.99   249          4.6     1,358   72%   18%   \n",
       "16                          NaN   NaN          NaN       NaN   NaN   NaN   \n",
       "17                        10.69   192          4.6       386   74%   14%   \n",
       "18                        19.38   234          4.4        56   73%    8%   \n",
       "19               36.00 - 49.99    442          4.9        14   90%   10%   \n",
       "\n",
       "   star3 star2 star1                 dimensions       weight language  \\\n",
       "0     6%   NaN   NaN     8.5 x 1.01 x 11 inches  2.53 pounds  English   \n",
       "1     9%    4%    6%     8 x 0.98 x 9.25 inches  1.96 pounds  English   \n",
       "2    NaN   NaN   NaN  8.25 x 0.6 x 10.75 inches   1.4 pounds  English   \n",
       "3     5%    2%    2%     7 x 1.11 x 9.19 inches  1.47 pounds  English   \n",
       "4    10%   10%   10%  7.38 x 0.83 x 9.25 inches   1.3 pounds  English   \n",
       "5    14%    4%    5%                        NaN          NaN      NaN   \n",
       "6     2%    2%    2%  6.75 x 0.75 x 8.75 inches   1.2 pounds  English   \n",
       "7     4%    2%   NaN     8.5 x 0.92 x 11 inches  2.15 pounds  English   \n",
       "8    NaN   NaN   NaN  6.75 x 0.75 x 9.75 inches  1.28 pounds  English   \n",
       "9    11%   NaN   NaN   7.38 x 1.5 x 9.25 inches  2.62 pounds  English   \n",
       "10    7%    3%    3%         6 x 0.9 x 9 inches  1.01 pounds  English   \n",
       "11    1%   NaN   NaN        6 x 0.24 x 9 inches   7.5 ounces  English   \n",
       "12    7%    3%    4%                        NaN          NaN      NaN   \n",
       "13    7%   NaN   NaN        6 x 1.19 x 9 inches  1.93 pounds  English   \n",
       "14   NaN   NaN   NaN   7.38 x 1.1 x 9.25 inches  1.75 pounds  English   \n",
       "15    7%    1%    2%   7.5 x 0.57 x 9.25 inches  15.5 ounces  English   \n",
       "16   NaN   NaN   NaN                        NaN          NaN      NaN   \n",
       "17    8%    2%    2%      7.25 x 0.5 x 9 inches  15.2 ounces  English   \n",
       "18   10%    4%    4%        6 x 0.53 x 9 inches  11.4 ounces  Spanish   \n",
       "19   NaN   NaN   NaN      7.5 x 1 x 9.25 inches  1.67 pounds  English   \n",
       "\n",
       "                                            publisher  \\\n",
       "0      Notion Press Media Pvt Ltd (November 22, 2021)   \n",
       "1       O'Reilly Media; 1st edition (August 18, 2009)   \n",
       "2   Holy Macro! Books; Third edition (August 1, 2022)   \n",
       "3     O'Reilly Media; 2nd edition (November 14, 2017)   \n",
       "4         For Dummies; 5th edition (February 3, 2022)   \n",
       "5                                                 NaN   \n",
       "6       O'Reilly Media; 1st edition (October 5, 2021)   \n",
       "7   SAGE Publications, Inc; 4th edition (January 2...   \n",
       "8   Cambridge University Press; 1st edition (March...   \n",
       "9                  Manning; 3rd edition (May 3, 2022)   \n",
       "10     University of Chicago Press (October 15, 2021)   \n",
       "11       Independently published (September 21, 2022)   \n",
       "12                                                NaN   \n",
       "13              Kenneth M Fornari (November 10, 2022)   \n",
       "14                         Manning (October 18, 2022)   \n",
       "15  ClydeBank Media LLC; Illustrated edition (Nove...   \n",
       "16                                                NaN   \n",
       "17  In Easy Steps Limited; 2nd edition (August 28,...   \n",
       "18              Independently published (May 2, 2020)   \n",
       "19                Packt Publishing (October 31, 2022)   \n",
       "\n",
       "                        ISBN_13  \\\n",
       "0                978-1685549596   \n",
       "1                978-0596153939   \n",
       "2                978-1615470747   \n",
       "3                978-1491957660   \n",
       "4                978-1119844426   \n",
       "5                           NaN   \n",
       "6                978-1492088783   \n",
       "7   Research in Drama Education   \n",
       "8                978-1108838658   \n",
       "9                978-1617296055   \n",
       "10               978-0226806433   \n",
       "11               979-8354008353   \n",
       "12                          NaN   \n",
       "13                                \n",
       "14                                \n",
       "15               978-1945051753   \n",
       "16                          NaN   \n",
       "17               978-1840788129   \n",
       "18               979-8642649534   \n",
       "19                                \n",
       "\n",
       "                                                 link  \\\n",
       "0   /Data-Analysis-Using-Low-Priced/dp/1685549594/...   \n",
       "1   /Head-First-Data-Analysis-statistics/dp/059615...   \n",
       "2   /Guerrilla-Analysis-Using-Microsoft-Excel/dp/1...   \n",
       "3   /Python-Data-Analysis-Wrangling-IPython/dp/149...   \n",
       "4   /Excel-Data-Analysis-Dummies-Computer/dp/11198...   \n",
       "5   /Everything-Data-Analytics-Beginners-Understan...   \n",
       "6   /SQL-Data-Analysis-Techniques-Transforming/dp/...   \n",
       "7   /Qualitative-Data-Analysis-Methods-Sourcebook/...   \n",
       "8   /Topological-Analysis-Applications-Gunnar-Carl...   \n",
       "9   /Action-Third-Robert-I-Kabacoff/dp/1617296058/...   \n",
       "10  /Listening-People-Interviewing-Participant-Obs...   \n",
       "11  /gp/slredirect/picassoRedirect.html/ref=pa_sp_...   \n",
       "12  /Python-Beginners-Perfect-Learning-Workbook/dp...   \n",
       "13  /gp/slredirect/picassoRedirect.html/ref=pa_sp_...   \n",
       "14  /Getting-Started-Natural-Language-Processing/d...   \n",
       "15  /gp/slredirect/picassoRedirect.html/ref=pa_sp_...   \n",
       "16  /Monty-Python-Grail-Graham-Chapman/dp/B07PGCJM...   \n",
       "17  /Python-easy-steps-Covers-3-7/dp/1840788127/re...   \n",
       "18  /Python-para-Principiantes-Programaci%C3%B3n-p...   \n",
       "19  /gp/slredirect/picassoRedirect.html/ref=pa_sp_...   \n",
       "\n",
       "                                        complete_link  \n",
       "0   https://www.amazon.com/Data-Analysis-Using-Low...  \n",
       "1   https://www.amazon.com/Head-First-Data-Analysi...  \n",
       "2   https://www.amazon.com/Guerrilla-Analysis-Usin...  \n",
       "3   https://www.amazon.com/Python-Data-Analysis-Wr...  \n",
       "4   https://www.amazon.com/Excel-Data-Analysis-Dum...  \n",
       "5   https://www.amazon.com/Everything-Data-Analyti...  \n",
       "6   https://www.amazon.com/SQL-Data-Analysis-Techn...  \n",
       "7   https://www.amazon.com/Qualitative-Data-Analys...  \n",
       "8   https://www.amazon.com/Topological-Analysis-Ap...  \n",
       "9   https://www.amazon.com/Action-Third-Robert-I-K...  \n",
       "10  https://www.amazon.com/Listening-People-Interv...  \n",
       "11  https://www.amazon.com/gp/slredirect/picassoRe...  \n",
       "12  https://www.amazon.com/Python-Beginners-Perfec...  \n",
       "13  https://www.amazon.com/gp/slredirect/picassoRe...  \n",
       "14  https://www.amazon.com/Getting-Started-Natural...  \n",
       "15  https://www.amazon.com/gp/slredirect/picassoRe...  \n",
       "16  https://www.amazon.com/Monty-Python-Grail-Grah...  \n",
       "17  https://www.amazon.com/Python-easy-steps-Cover...  \n",
       "18  https://www.amazon.com/Python-para-Principiant...  \n",
       "19  https://www.amazon.com/gp/slredirect/picassoRe...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "df = pd.read_csv('final_book_dataset_kaggle2.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc796a",
   "metadata": {},
   "source": [
    "### Checking basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483b5b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'author', 'price', 'price (including used books)', 'pages',\n",
       "       'avg_reviews', 'n_reviews', 'star5', 'star4', 'star3', 'star2', 'star1',\n",
       "       'dimensions', 'weight', 'language', 'publisher', 'ISBN_13', 'link',\n",
       "       'complete_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f44f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 830 entries, 0 to 829\n",
      "Data columns (total 19 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   title                         830 non-null    object \n",
      " 1   author                        657 non-null    object \n",
      " 2   price                         722 non-null    float64\n",
      " 3   price (including used books)  722 non-null    object \n",
      " 4   pages                         745 non-null    object \n",
      " 5   avg_reviews                   702 non-null    float64\n",
      " 6   n_reviews                     702 non-null    object \n",
      " 7   star5                         702 non-null    object \n",
      " 8   star4                         635 non-null    object \n",
      " 9   star3                         554 non-null    object \n",
      " 10  star2                         451 non-null    object \n",
      " 11  star1                         328 non-null    object \n",
      " 12  dimensions                    644 non-null    object \n",
      " 13  weight                        651 non-null    object \n",
      " 14  language                      759 non-null    object \n",
      " 15  publisher                     714 non-null    object \n",
      " 16  ISBN_13                       665 non-null    object \n",
      " 17  link                          830 non-null    object \n",
      " 18  complete_link                 830 non-null    object \n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 123.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42f4d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                             0\n",
       "author                          173\n",
       "price                           108\n",
       "price (including used books)    108\n",
       "pages                            85\n",
       "avg_reviews                     128\n",
       "n_reviews                       128\n",
       "star5                           128\n",
       "star4                           195\n",
       "star3                           276\n",
       "star2                           379\n",
       "star1                           502\n",
       "dimensions                      186\n",
       "weight                          179\n",
       "language                         71\n",
       "publisher                       116\n",
       "ISBN_13                         165\n",
       "link                              0\n",
       "complete_link                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30800576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>20.843373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>13.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price (including used books)</th>\n",
       "      <td>13.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pages</th>\n",
       "      <td>10.240964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_reviews</th>\n",
       "      <td>15.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_reviews</th>\n",
       "      <td>15.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star5</th>\n",
       "      <td>15.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star4</th>\n",
       "      <td>23.493976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star3</th>\n",
       "      <td>33.253012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star2</th>\n",
       "      <td>45.662651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star1</th>\n",
       "      <td>60.481928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions</th>\n",
       "      <td>22.409639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>21.566265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>8.554217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher</th>\n",
       "      <td>13.975904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN_13</th>\n",
       "      <td>19.879518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complete_link</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Percent Missing\n",
       "title                                0.000000\n",
       "author                              20.843373\n",
       "price                               13.012048\n",
       "price (including used books)        13.012048\n",
       "pages                               10.240964\n",
       "avg_reviews                         15.421687\n",
       "n_reviews                           15.421687\n",
       "star5                               15.421687\n",
       "star4                               23.493976\n",
       "star3                               33.253012\n",
       "star2                               45.662651\n",
       "star1                               60.481928\n",
       "dimensions                          22.409639\n",
       "weight                              21.566265\n",
       "language                             8.554217\n",
       "publisher                           13.975904\n",
       "ISBN_13                             19.879518\n",
       "link                                 0.000000\n",
       "complete_link                        0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check percentage of missing data\n",
    "missing_data = df.isnull().sum() * 100/len(df)\n",
    "percent_missing = pd.DataFrame({'Percent Missing' : missing_data})\n",
    "percent_missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ef754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091d66f",
   "metadata": {},
   "source": [
    "### Check Object Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8fe125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price (including used books)</th>\n",
       "      <th>pages</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>weight</th>\n",
       "      <th>language</th>\n",
       "      <th>publisher</th>\n",
       "      <th>ISBN_13</th>\n",
       "      <th>link</th>\n",
       "      <th>complete_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Generic Data Structures and Algorithms in Go: ...</td>\n",
       "      <td>[ Richard Wiener]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Generic-Data-Structures-Algorithms-Concurrenc...</td>\n",
       "      <td>https://www.amazon.com/Generic-Data-Structures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>The Art of Statistics: How to Learn from Data</td>\n",
       "      <td>[ David Spiegelhalter]</td>\n",
       "      <td>17.99</td>\n",
       "      <td>448</td>\n",
       "      <td>2,906</td>\n",
       "      <td>73%</td>\n",
       "      <td>19%</td>\n",
       "      <td>6%</td>\n",
       "      <td>1%</td>\n",
       "      <td>2%</td>\n",
       "      <td>5.5 x 1.25 x 8.5 inches</td>\n",
       "      <td>13.3 ounces</td>\n",
       "      <td>English</td>\n",
       "      <td>Basic Books (August 17, 2021)</td>\n",
       "      <td>978-1541675704</td>\n",
       "      <td>/Art-Statistics-How-Learn-Data/dp/1541675703/r...</td>\n",
       "      <td>https://www.amazon.com/Art-Statistics-How-Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Learning R: A Step-by-Step Function Guide to D...</td>\n",
       "      <td>[ Richard Cotton]</td>\n",
       "      <td>37.82 - 40.99</td>\n",
       "      <td>396</td>\n",
       "      <td>162</td>\n",
       "      <td>65%</td>\n",
       "      <td>23%</td>\n",
       "      <td>6%</td>\n",
       "      <td>2%</td>\n",
       "      <td>4%</td>\n",
       "      <td>7 x 0.82 x 9.19 inches</td>\n",
       "      <td>1.43 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 1st edition (October 22, 2013)</td>\n",
       "      <td>978-1449357108</td>\n",
       "      <td>/Learning-Step-Step-Function-Analysis/dp/14493...</td>\n",
       "      <td>https://www.amazon.com/Learning-Step-Step-Func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Data Literacy in Practice: A complete guide to...</td>\n",
       "      <td>[ Angelika Klidas,  and , Kevin Hanegan]</td>\n",
       "      <td>44.99 - 54.44</td>\n",
       "      <td>396</td>\n",
       "      <td>2</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5 x 0.9 x 9.25 inches</td>\n",
       "      <td>1.5 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Packt Publishing (November 30, 2022)</td>\n",
       "      <td></td>\n",
       "      <td>/gp/slredirect/picassoRedirect.html/ref=pa_sp_...</td>\n",
       "      <td>https://www.amazon.com/gp/slredirect/picassoRe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Data Structures &amp; Algorithms in Python (Develo...</td>\n",
       "      <td>[ John Canning, Alan Broder, et al.]</td>\n",
       "      <td>57.79 - 69.99</td>\n",
       "      <td>928</td>\n",
       "      <td>3</td>\n",
       "      <td>100%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7 x 1.21 x 9.13 inches</td>\n",
       "      <td>2.93 pounds</td>\n",
       "      <td>English</td>\n",
       "      <td>Addison-Wesley Professional; 1st edition (Octo...</td>\n",
       "      <td>978-0134855684</td>\n",
       "      <td>/Structures-Algorithms-Python-Robert-Lafore/dp...</td>\n",
       "      <td>https://www.amazon.com/Structures-Algorithms-P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "738  Generic Data Structures and Algorithms in Go: ...   \n",
       "659      The Art of Statistics: How to Learn from Data   \n",
       "291  Learning R: A Step-by-Step Function Guide to D...   \n",
       "370  Data Literacy in Practice: A complete guide to...   \n",
       "321  Data Structures & Algorithms in Python (Develo...   \n",
       "\n",
       "                                       author price (including used books)  \\\n",
       "738                         [ Richard Wiener]                          NaN   \n",
       "659                    [ David Spiegelhalter]                        17.99   \n",
       "291                         [ Richard Cotton]               37.82 - 40.99    \n",
       "370  [ Angelika Klidas,  and , Kevin Hanegan]               44.99 - 54.44    \n",
       "321      [ John Canning, Alan Broder, et al.]               57.79 - 69.99    \n",
       "\n",
       "    pages n_reviews star5 star4 star3 star2 star1               dimensions  \\\n",
       "738   NaN       NaN   NaN   NaN   NaN   NaN   NaN                      NaN   \n",
       "659   448     2,906   73%   19%    6%    1%    2%  5.5 x 1.25 x 8.5 inches   \n",
       "291   396       162   65%   23%    6%    2%    4%   7 x 0.82 x 9.19 inches   \n",
       "370   396         2  100%   NaN   NaN   NaN   NaN  7.5 x 0.9 x 9.25 inches   \n",
       "321   928         3  100%   NaN   NaN   NaN   NaN   7 x 1.21 x 9.13 inches   \n",
       "\n",
       "          weight language                                          publisher  \\\n",
       "738          NaN      NaN                                                NaN   \n",
       "659  13.3 ounces  English                      Basic Books (August 17, 2021)   \n",
       "291  1.43 pounds  English     O'Reilly Media; 1st edition (October 22, 2013)   \n",
       "370   1.5 pounds  English               Packt Publishing (November 30, 2022)   \n",
       "321  2.93 pounds  English  Addison-Wesley Professional; 1st edition (Octo...   \n",
       "\n",
       "            ISBN_13                                               link  \\\n",
       "738             NaN  /Generic-Data-Structures-Algorithms-Concurrenc...   \n",
       "659  978-1541675704  /Art-Statistics-How-Learn-Data/dp/1541675703/r...   \n",
       "291  978-1449357108  /Learning-Step-Step-Function-Analysis/dp/14493...   \n",
       "370                  /gp/slredirect/picassoRedirect.html/ref=pa_sp_...   \n",
       "321  978-0134855684  /Structures-Algorithms-Python-Robert-Lafore/dp...   \n",
       "\n",
       "                                         complete_link  \n",
       "738  https://www.amazon.com/Generic-Data-Structures...  \n",
       "659  https://www.amazon.com/Art-Statistics-How-Lear...  \n",
       "291  https://www.amazon.com/Learning-Step-Step-Func...  \n",
       "370  https://www.amazon.com/gp/slredirect/picassoRe...  \n",
       "321  https://www.amazon.com/Structures-Algorithms-P...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_variables = df.select_dtypes(object).sample(5)\n",
    "obj_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d64a6b",
   "metadata": {},
   "source": [
    "### STEPS TO TAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b62085a",
   "metadata": {},
   "source": [
    "1. Replace missing values in pages with the average and clean the column\n",
    "\n",
    "2. Rename the 'price (including used books)' column, replace NAN values with the average, and clean the column\n",
    "\n",
    "3. Remove the ' [ ' and ' ] ' and any other characters from the author column and replace the missing values\n",
    "\n",
    "4. Clean the n_reviews columns.\n",
    "\n",
    "5. Clean the star columns\n",
    "\n",
    "6. Convert the dimensions column to cm and replace null values with 0\n",
    "\n",
    "7. convert all other units of measurements in the weight column with pounds and replace null values with 0\n",
    "\n",
    "8. Split the rows in publisher column with date to another column and replace null values\n",
    "\n",
    "9. Drop unnecessary columns \n",
    "\n",
    "10. Replace missing values in other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec5bf2",
   "metadata": {},
   "source": [
    "### 1. Replace missing values in pages with the average and clean the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e368f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    484\n",
       "2    274\n",
       "3    547\n",
       "4    368\n",
       "5    NaN\n",
       "6    360\n",
       "7    408\n",
       "8    230\n",
       "9    656\n",
       "Name: pages, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pages'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f7709",
   "metadata": {},
   "source": [
    "The datatype for the pages column is object. Let's check to see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841082c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['500', '484', '274', '547', '368', nan, '360', '408', '230', '656',\n",
       "       '333', '106', '528', '456', '249', '192', '234', '442', '301',\n",
       "       '338', '550', '280', '1012', '88', '328', '24', '224', '387',\n",
       "       '289', '100', '380', '240', '464', '559', '175', '397', '332',\n",
       "       '630', '458', '720', '488', '392', '824', '304', '459', '384',\n",
       "       '346', '276', '880', '716', '376', '745', '592', '640', '216',\n",
       "       '118', '432', '128', '256', '129', '271', '526', '306', '400',\n",
       "       '440', '147', '402', '576', '226', '472', '568', '506', '734',\n",
       "       '131', '222', '266', '394', '352', '1040', '399', '125', '146',\n",
       "       '608', '336', '350', '330', '832', '272', '1096', '178', '386',\n",
       "       '560', '149',\n",
       "       'Explores all features and functions in two-color  packed with screenshots, numbered steps, and other visual graphics that clearly show you how to accomplish tasks',\n",
       "       '416', '379', '553', '483', '732', '712', '984', '428', '74', '6',\n",
       "       '161', '536', '510', '205', '414', '586', '168', '322', '944',\n",
       "       '422', '49', '616', '396', '864', '810', '624', '180', '212',\n",
       "       '540', '948', '354', '444', '320', '300', '480', '153', '658',\n",
       "       '768', '242', '611', '410', '342', '198', '305', '660', '420',\n",
       "       '238', '562', '220', '201', '752', '264', '744', '200', '478',\n",
       "       '566', '335', '784', '287', '921', '406', '1292', '544', '1004',\n",
       "       '366', '612', '312', '296', '423', '126', '393', '154', '476',\n",
       "       '141', '344', '381', '278',\n",
       "       ' for creating superior text  in just a few minutes', '491', '520',\n",
       "       '664', '244', '508', '162', '114', '552', '138', '159', '504',\n",
       "       '620', '644', '119', '324', '150', '426', '1296', '754', '164',\n",
       "       '848', '496', 'Extract data from APIs and web ', '208', '260',\n",
       "       '584', '155', '288', '355', '682', '534', '313', '788', '530',\n",
       "       '62', '452', '248', '120', '650', '928', '82', '684', '518', '448',\n",
       "       '347', '255', '736', '112', '67', '600', '279', '800', '450',\n",
       "       '134', '167', '626', '676', '358', '362',\n",
       "       'Expand your app by creating dynamic  that generate content based on URLs',\n",
       "       '251', '688', '470', '497', '143', '738', '1168', '579', '382',\n",
       "       '637', '121', '1,000', '594', '375', '390', '766', '424', '160',\n",
       "       'Develop web  and programs with Python tools and packages', '603',\n",
       "       '704', '345', '659', '107', '174', '764', '468', '564', '269',\n",
       "       '41', '56', '334', '206', '498', '412', '165', '1456', '606',\n",
       "       '108', '103', '101', '130', '343', '284', '252', '516', '236',\n",
       "       '151', '70', '856', '144', '286', '176', '10', '438', '58', '68',\n",
       "       '250', '145', '22', '356', '436', '826', '454', '474', '551',\n",
       "       '425', '135', '723', '570', '502', '196', '290',\n",
       "       'Parse complicated HTML  ', '455', '590', '310', '171', '398',\n",
       "       '172', '714', '231', '77', '163', '241', '142', '493', '191',\n",
       "       '  of high quality paper', '308', '48', '262', '601', '32', '232',\n",
       "       '190', '507', '1650', '1643', '705', '372', '2962', '614', '521',\n",
       "       '166', '512', '446', '318', '326', '370', '462', '170', '572',\n",
       "       '31', '415', '340', '430', '59', '314', '98', '243', '316', '822',\n",
       "       '555', '460', '364', '311', '186', '94', '482', '748', '181',\n",
       "       '210', '270', '558', '687', '158', '522', '258', '667', '195',\n",
       "       '378', 'Full-color , showcasing all 24 final data visualizations',\n",
       "       '774', '573'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pages'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e910686",
   "metadata": {},
   "source": [
    "Some values are in string format so we'll convert them to a numeric type and fill them with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19ffbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      500\n",
       "1      484\n",
       "2      274\n",
       "3      547\n",
       "4      368\n",
       "      ... \n",
       "825    208\n",
       "826    573\n",
       "827    288\n",
       "828      0\n",
       "829      0\n",
       "Name: pages, Length: 830, dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert non-integer values to numeric\n",
    "df['pages'] = pd.to_numeric(df['pages'], errors = 'coerce').fillna(0).astype(int)\n",
    "df['pages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89116fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill missing values with 0\n",
    "df['pages'].fillna('0', inplace = True)\n",
    "df['pages'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da44b7d6",
   "metadata": {},
   "source": [
    "### 2. Rename the 'price (including used books)' column, clean the column, and replace NAN values with the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf7b6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'price (including used books)':'all_prices'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd72eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 6.75\n",
       "1       21.49 - 33.72 \n",
       "2                32.07\n",
       "3                53.99\n",
       "4                24.49\n",
       "            ...       \n",
       "825      8.55 - 35.33 \n",
       "826     52.41 - 55.18 \n",
       "827              44.99\n",
       "828                NaN\n",
       "829              38.49\n",
       "Name: all_prices, Length: 830, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['all_prices']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f86e4",
   "metadata": {},
   "source": [
    "There are certain values in the all_prices column that reflect the costs of both new and used books. We'll calculate the average of these numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be40249f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6.750\n",
       "1      27.605\n",
       "2      32.070\n",
       "3      53.990\n",
       "4      24.490\n",
       "        ...  \n",
       "825    21.940\n",
       "826    53.795\n",
       "827    44.990\n",
       "828       NaN\n",
       "829    38.490\n",
       "Name: average_value, Length: 830, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the minimum and maximum values from range values and compute their average\n",
    "def price_average(val):\n",
    "    if isinstance(val, str) and '-' in val:\n",
    "        min_value, max_value = map(float, val.split('-'))\n",
    "        return (min_value + max_value) / 2\n",
    "    else:\n",
    "        try:\n",
    "            return float(val)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "# Apply the function to the column and create a new column\n",
    "df['average_value'] = df['all_prices'].apply(price_average)\n",
    "\n",
    "# Print the updated dataframe\n",
    "df['average_value'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ad535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average_value'].fillna(df['average_value'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "793ff246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6.75\n",
       "1      27.60\n",
       "2      32.07\n",
       "3      53.99\n",
       "4      24.49\n",
       "       ...  \n",
       "825    21.94\n",
       "826    53.80\n",
       "827    44.99\n",
       "828    43.06\n",
       "829    38.49\n",
       "Name: average_value, Length: 830, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Round to 2 decimal places\n",
    "np.round(df['average_value'], decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc141a43",
   "metadata": {},
   "source": [
    "### 3. Remove the ' [ ' and ' ] ' and any other characters from the author column and replace the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7447e4b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [ Dr Dhaval Maheta]\n",
       "1                                   NaN\n",
       "2    [ Oz du Soleil,  and , Bill Jelen]\n",
       "3                   [ William McKinney]\n",
       "4                     [ Paul McFedries]\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d760ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_col(x):\n",
    "    if x == x:\n",
    "        return x.lstrip('[ ').rstrip(']').replace(',  and ,', ' and')\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84b9a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df['author'].apply(author_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee410d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Dr Dhaval Maheta\n",
       "1                            NaN\n",
       "2    Oz du Soleil and Bill Jelen\n",
       "3               William McKinney\n",
       "4                 Paul McFedries\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8542fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'].fillna('No Name', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f9141f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Dr Dhaval Maheta\n",
       "1                        No Name\n",
       "2    Oz du Soleil and Bill Jelen\n",
       "3               William McKinney\n",
       "4                 Paul McFedries\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd04df1",
   "metadata": {},
   "source": [
    "### 4. Clean the n_reviews column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78358089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238        6\n",
       "825       74\n",
       "448      NaN\n",
       "195       61\n",
       "78       463\n",
       "289      161\n",
       "86       NaN\n",
       "369       49\n",
       "43        16\n",
       "701    1,123\n",
       "Name: n_reviews, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_reviews'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c46ca",
   "metadata": {},
   "source": [
    "All values in thousands have a comma. We'll remove the commas to make them integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca1cef54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         23\n",
       "1        124\n",
       "2         10\n",
       "3      1,686\n",
       "4         12\n",
       "       ...  \n",
       "825       74\n",
       "826       93\n",
       "827        8\n",
       "828      NaN\n",
       "829      142\n",
       "Name: n_reviews, Length: 830, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caf57a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace commas in string values and leave NaN values as is\n",
    "df['n_reviews'] = df['n_reviews'].apply(lambda x: str(x).replace(',', '') if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e00107fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace null values with 0\n",
    "#df['n_reviews'].fillna('0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39f897e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        23\n",
       "1       124\n",
       "2        10\n",
       "3      1686\n",
       "4        12\n",
       "       ... \n",
       "825      74\n",
       "826      93\n",
       "827       8\n",
       "828       0\n",
       "829     142\n",
       "Name: n_reviews, Length: 830, dtype: int32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to integer data type and replace null values with 0\n",
    "df['n_reviews'] = pd.to_numeric(df['n_reviews'], errors = 'coerce').fillna(0).astype(int)\n",
    "df['n_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809313f",
   "metadata": {},
   "source": [
    "### 5. Clean the star column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a2d7d",
   "metadata": {},
   "source": [
    "Fill the null values in star columns with 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce72c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['star5'].fillna('0', inplace = True)\n",
    "df['star4'].fillna('0', inplace = True)\n",
    "df['star3'].fillna('0', inplace = True)\n",
    "df['star2'].fillna('0', inplace = True)\n",
    "df['star1'].fillna('0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e5c9687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55%</td>\n",
       "      <td>39%</td>\n",
       "      <td>6%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61%</td>\n",
       "      <td>20%</td>\n",
       "      <td>9%</td>\n",
       "      <td>4%</td>\n",
       "      <td>6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87%</td>\n",
       "      <td>13%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75%</td>\n",
       "      <td>16%</td>\n",
       "      <td>5%</td>\n",
       "      <td>2%</td>\n",
       "      <td>2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52%</td>\n",
       "      <td>17%</td>\n",
       "      <td>10%</td>\n",
       "      <td>10%</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>72%</td>\n",
       "      <td>14%</td>\n",
       "      <td>7%</td>\n",
       "      <td>2%</td>\n",
       "      <td>4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>78%</td>\n",
       "      <td>7%</td>\n",
       "      <td>7%</td>\n",
       "      <td>4%</td>\n",
       "      <td>4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>83%</td>\n",
       "      <td>17%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>79%</td>\n",
       "      <td>15%</td>\n",
       "      <td>4%</td>\n",
       "      <td>1%</td>\n",
       "      <td>1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    star5 star4 star3 star2 star1\n",
       "0     55%   39%    6%     0     0\n",
       "1     61%   20%    9%    4%    6%\n",
       "2     87%   13%     0     0     0\n",
       "3     75%   16%    5%    2%    2%\n",
       "4     52%   17%   10%   10%   10%\n",
       "..    ...   ...   ...   ...   ...\n",
       "825   72%   14%    7%    2%    4%\n",
       "826   78%    7%    7%    4%    4%\n",
       "827   83%   17%     0     0     0\n",
       "828     0     0     0     0     0\n",
       "829   79%   15%    4%    1%    1%\n",
       "\n",
       "[830 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['star5', 'star4', 'star3', 'star2', 'star1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a9b34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the percentage sign from the columns and convert it to a float, dividing by 100.\n",
    "def strip_and_convert_to_float(df, column_name):\n",
    "    df[column_name] = df[column_name].str.rstrip('%').astype(float) / 100\n",
    "\n",
    "strip_and_convert_to_float(df, 'star5')\n",
    "strip_and_convert_to_float(df, 'star4')\n",
    "strip_and_convert_to_float(df, 'star3')\n",
    "strip_and_convert_to_float(df, 'star2')\n",
    "strip_and_convert_to_float(df, 'star1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84a7a308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star5</th>\n",
       "      <th>star4</th>\n",
       "      <th>star3</th>\n",
       "      <th>star2</th>\n",
       "      <th>star1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     star5  star4  star3  star2  star1\n",
       "0     0.55   0.39   0.06   0.00   0.00\n",
       "1     0.61   0.20   0.09   0.04   0.06\n",
       "2     0.87   0.13   0.00   0.00   0.00\n",
       "3     0.75   0.16   0.05   0.02   0.02\n",
       "4     0.52   0.17   0.10   0.10   0.10\n",
       "..     ...    ...    ...    ...    ...\n",
       "825   0.72   0.14   0.07   0.02   0.04\n",
       "826   0.78   0.07   0.07   0.04   0.04\n",
       "827   0.83   0.17   0.00   0.00   0.00\n",
       "828   0.00   0.00   0.00   0.00   0.00\n",
       "829   0.79   0.15   0.04   0.01   0.01\n",
       "\n",
       "[830 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['star5', 'star4', 'star3', 'star2', 'star1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b06b2",
   "metadata": {},
   "source": [
    "### 6. Convert the dimensions column to cm and replace null values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "794a27a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         8.5 x 1.01 x 11 inches\n",
       "1         8 x 0.98 x 9.25 inches\n",
       "2      8.25 x 0.6 x 10.75 inches\n",
       "3         7 x 1.11 x 9.19 inches\n",
       "4      7.38 x 0.83 x 9.25 inches\n",
       "                 ...            \n",
       "825         7 x 0.47 x 10 inches\n",
       "826    6.14 x 1.25 x 9.21 inches\n",
       "827     7.5 x 0.65 x 9.25 inches\n",
       "828                          NaN\n",
       "829                          NaN\n",
       "Name: dimensions, Length: 830, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dimensions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d38f5085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         8.5 x 1.01 x 11 \n",
       "1         8 x 0.98 x 9.25 \n",
       "2      8.25 x 0.6 x 10.75 \n",
       "3         7 x 1.11 x 9.19 \n",
       "4      7.38 x 0.83 x 9.25 \n",
       "              ...         \n",
       "825         7 x 0.47 x 10 \n",
       "826    6.14 x 1.25 x 9.21 \n",
       "827     7.5 x 0.65 x 9.25 \n",
       "828                    NaN\n",
       "829                    NaN\n",
       "Name: dimensions, Length: 830, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the inches unit of measurement\n",
    "df['dimensions'] = df['dimensions'].str.rstrip('inches')\n",
    "df['dimensions'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e914340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      94.44\n",
       "1      72.52\n",
       "2      53.21\n",
       "3      71.41\n",
       "4      56.66\n",
       "       ...  \n",
       "825    32.90\n",
       "826    70.69\n",
       "827    45.09\n",
       "828      NaN\n",
       "829      NaN\n",
       "Name: dimensions(cm), Length: 830, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to convert inches to cm\n",
    "def inch_to_cm(x):\n",
    "    try:\n",
    "        x = str(x)\n",
    "        if 'x' in x:\n",
    "            nums = [float(num.strip()) * 2.54 for num in x.split('x')]\n",
    "            if len(nums) == 3:\n",
    "                volume = nums[0] * nums[1] * nums[2] / 16.387\n",
    "                return round(volume, 2)\n",
    "            else:\n",
    "                return sum(nums)\n",
    "        else:\n",
    "            return float(x) * 2.54\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Create a new column with the converted values\n",
    "df['dimensions(cm)'] = df['dimensions'].apply(inch_to_cm)\n",
    "\n",
    "df['dimensions(cm)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22974fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      94.44\n",
       "1      72.52\n",
       "2      53.21\n",
       "3      71.41\n",
       "4      56.66\n",
       "       ...  \n",
       "825    32.90\n",
       "826    70.69\n",
       "827    45.09\n",
       "828     0.00\n",
       "829     0.00\n",
       "Name: dimensions(cm), Length: 830, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dimensions(cm)'] = pd.to_numeric(df['dimensions(cm)'], errors = 'coerce').fillna(0).astype(float)\n",
    "df['dimensions(cm)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce1b52",
   "metadata": {},
   "source": [
    "### 7. convert all other units of measurements in the weight column with pounds and replace null values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98cb1370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2.53 pounds', '1.96 pounds', '1.4 pounds', '1.47 pounds',\n",
       "       '1.3 pounds', nan, '1.2 pounds', '2.15 pounds', '1.28 pounds',\n",
       "       '2.62 pounds', '1.01 pounds', '7.5 ounces', '1.93 pounds',\n",
       "       '1.75 pounds', '15.5 ounces', '15.2 ounces', '11.4 ounces',\n",
       "       '1.67 pounds', '14.3 ounces', '1.19 pounds', '2.04 pounds',\n",
       "       '1.16 pounds', '3.53 ounces', '9.9 ounces', '1.5 pounds',\n",
       "       '3.04 ounces', '1.54 pounds', '1.14 pounds', '13 ounces',\n",
       "       '1.94 pounds', '2.8 pounds', '1.33 pounds', '14.4 ounces',\n",
       "       '2.36 pounds', '2.05 pounds', '1.45 pounds', '2.4 pounds',\n",
       "       '1.7 pounds', '1.52 pounds', '3.95 pounds', '7.1 ounces',\n",
       "       '1.65 pounds', '1.46 pounds', '1.06 pounds', '2.83 pounds',\n",
       "       '1.41 pounds', '30.2 pounds', '1.85 pounds', '1.51 pounds',\n",
       "       '1 pounds', '1.35 pounds', '4.6 ounces', '2.01 pounds',\n",
       "       '1.66 pounds', '1.1 pounds', '9 ounces', '14.1 ounces',\n",
       "       '2.42 pounds', '1.09 pounds', '1.63 pounds', '1.64 pounds',\n",
       "       '1.6 pounds', '11.5 ounces', '2.48 pounds', '13.9 ounces',\n",
       "       '1.34 pounds', '1.02 pounds', '1.04 pounds', '1.39 pounds',\n",
       "       '1.55 pounds', '1.15 pounds', '4.45 pounds', '1.74 pounds',\n",
       "       '9.6 ounces', '1.98 pounds', '8 ounces', '1.25 pounds',\n",
       "       '1.37 pounds', '4.1 pounds', '11.2 ounces', '1.32 pounds',\n",
       "       '3.46 pounds', '12.8 ounces', '2.16 pounds', '1.11 pounds',\n",
       "       '1.79 pounds', '2.54 pounds', '1.87 pounds', '1.69 pounds',\n",
       "       '3.09 pounds', '12 ounces', '2.4 ounces', '1.08 pounds',\n",
       "       '1.91 pounds', '2.19 pounds', '7.8 ounces', '1.22 pounds',\n",
       "       '4.37 pounds', '1.59 pounds', '4.5 ounces', '1.81 pounds',\n",
       "       '1.07 pounds', '2.35 pounds', '13.3 ounces', '10.2 ounces',\n",
       "       '1.88 pounds', '10.5 ounces', '3.9 pounds', '2.07 pounds',\n",
       "       '1.9 pounds', '1.8 pounds', '16 ounces', '3 pounds', '2.24 ounces',\n",
       "       '3.04 pounds', '1.58 pounds', '13.1 ounces', '13.6 ounces',\n",
       "       '13.8 ounces', '3.15 pounds', '14.5 ounces', '2.77 pounds',\n",
       "       '2.12 pounds', '2.3 pounds', '2.95 pounds', '4.95 pounds',\n",
       "       '1.38 pounds', '2.28 pounds', '1.42 pounds', '3.17 pounds',\n",
       "       '3.35 pounds', '1.71 pounds', '8.8 ounces', '1.95 pounds',\n",
       "       '2.08 pounds', '2.38 pounds', '2.09 pounds', '6.7 ounces',\n",
       "       '2.6 pounds', '14.9 ounces', '2.89 pounds', '1.48 pounds',\n",
       "       '2.39 pounds', '1.83 pounds', '1.26 pounds', '11.3 ounces',\n",
       "       '2.47 pounds', '7 ounces', '5.1 pounds', '3.3 pounds',\n",
       "       '2.87 pounds', '6.1 ounces', '2.29 pounds', '9.8 ounces',\n",
       "       '8.3 ounces', '1.43 pounds', '1.05 pounds', '2 pounds',\n",
       "       '2.93 pounds', '1.27 pounds', '1.72 pounds', '1.89 pounds',\n",
       "       '1.12 pounds', '11.02 pounds', '2.27 pounds', '1.23 pounds',\n",
       "       '12.2 ounces', '14.6 ounces', '2.81 pounds', '15.9 ounces',\n",
       "       '1.13 pounds', '10.4 ounces', '8.2 ounces', '1.76 pounds',\n",
       "       '2.34 pounds', '3.43 pounds', '1.36 pounds', '14.7 ounces',\n",
       "       '3.05 pounds', '1.62 pounds', '2.96 pounds', '1.77 pounds',\n",
       "       '1.92 pounds', '5.3 ounces', '3.51 pounds', '4.12 pounds',\n",
       "       '1.44 pounds', '2.56 pounds', '2.11 pounds', '11.7 ounces',\n",
       "       '2.26 pounds', '3.94 pounds', '2.22 pounds', '3.55 pounds',\n",
       "       '2.24 pounds', '2.5 pounds', '3.7 pounds', '2.84 pounds',\n",
       "       '2.55 pounds', '2.21 pounds', '4.3 ounces', '1.17 pounds',\n",
       "       '1.56 pounds', '2.85 pounds', '2.25 pounds', '15.3 ounces',\n",
       "       '15 ounces', '4.61 pounds', '3.06 pounds', '2.73 pounds',\n",
       "       '13.4 ounces', '9.2 ounces', '14.2 ounces', '2.1 pounds',\n",
       "       '12.5 ounces', '15.8 ounces', '2.56 ounces', '8.1 ounces',\n",
       "       '1.78 pounds', '7.2 ounces', '3.07 pounds', '1.86 pounds',\n",
       "       '1.49 pounds', '2.99 pounds', '5.6 ounces', '2.14 pounds',\n",
       "       '1.21 pounds', '2.45 pounds', '2.66 pounds', '2.2 pounds',\n",
       "       '12.3 ounces', '13.7 ounces', '5.1 ounces', '1.44 ounces',\n",
       "       '1.57 pounds', '1.6 ounces', '6.6 ounces', '3.19 pounds',\n",
       "       '2.03 pounds', '1.03 pounds', '18.62 pounds', '2.32 pounds',\n",
       "       '1.82 pounds', '1.61 pounds', '3.73 pounds', '22.2 pounds',\n",
       "       '9.1 ounces', '2.37 pounds', '1.99 pounds', '2.41 pounds',\n",
       "       '3.52 ounces', '15.7 ounces', '1.29 pounds', '1.73 pounds',\n",
       "       '4.73 pounds', '5.51 pounds',\n",
       "       'I love the way Seth Stephens-Davidowitz explains how we can better live our lives by exploiting the small advantages in life. On the basketball court, I made a career out of finding these types of minor advantages, and I’ve found that most successful individuals in life value the accumulation of small advantages. In the end, they add up to significant life benefits. -- ',\n",
       "       '3.44 pounds', '2.61 pounds', '6.9 ounces', '2.78 pounds',\n",
       "       '14.8 ounces', '3.31 pounds', '11.8 ounces', '0.035 ounces',\n",
       "       '2.69 pounds', '3.25 pounds', '12.6 ounces', '8.4 ounces',\n",
       "       '11 ounces', '14.17 pounds', '4.23 pounds', '2.88 pounds',\n",
       "       '10.9 ounces'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weight'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ee9c0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2.53\n",
       "1         1.96\n",
       "2          1.4\n",
       "3         1.47\n",
       "4          1.3\n",
       "        ...   \n",
       "825    0.96875\n",
       "826       2.25\n",
       "827        1.1\n",
       "828        NaN\n",
       "829        NaN\n",
       "Name: weight, Length: 830, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to convert ounces to pounds\n",
    "def convert_to_pounds(val):\n",
    "    if isinstance(val, str) and 'ounces' in val:\n",
    "        ounces = float(val.split()[0])\n",
    "        return ounces / 16\n",
    "    elif isinstance(val, str) and 'pounds' in val:\n",
    "            pounds = float(val.split()[0])\n",
    "            return pounds\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "# apply the function to the 'Weight' column\n",
    "df['weight'] = df['weight'].apply(convert_to_pounds)\n",
    "\n",
    "df['weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf390db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.53000\n",
       "1      1.96000\n",
       "2      1.40000\n",
       "3      1.47000\n",
       "4      1.30000\n",
       "        ...   \n",
       "825    0.96875\n",
       "826    2.25000\n",
       "827    1.10000\n",
       "828    0.00000\n",
       "829    0.00000\n",
       "Name: weight, Length: 830, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the column to numeric type and fill null values with 0.\n",
    "df['weight'] = pd.to_numeric(df['weight'], errors = 'coerce').fillna(0).astype(float)\n",
    "df['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c329c3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.53\n",
       "1      1.96\n",
       "2      1.40\n",
       "3      1.47\n",
       "4      1.30\n",
       "       ... \n",
       "825    0.97\n",
       "826    2.25\n",
       "827    1.10\n",
       "828    0.00\n",
       "829    0.00\n",
       "Name: weight, Length: 830, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Round to 2 decimal places\n",
    "np.round(df['weight'], decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741de164",
   "metadata": {},
   "source": [
    "### 8. Split the rows in publisher column with date to another column and replace null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86336790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Notion Press Media Pvt Ltd (November 22, 2021)\n",
       "1          O'Reilly Media; 1st edition (August 18, 2009)\n",
       "2      Holy Macro! Books; Third edition (August 1, 2022)\n",
       "3        O'Reilly Media; 2nd edition (November 14, 2017)\n",
       "4            For Dummies; 5th edition (February 3, 2022)\n",
       "                             ...                        \n",
       "825            Corwin; First edition (December 15, 2017)\n",
       "826        Springer; 1st ed. 2020 edition (July 2, 2020)\n",
       "827                      Packt Publishing (July 8, 2022)\n",
       "828                                                  NaN\n",
       "829                                                  NaN\n",
       "Name: publisher, Length: 830, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['publisher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a3322ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2021-11-22\n",
       "1     2009-08-18\n",
       "2     2022-08-01\n",
       "3     2017-11-14\n",
       "4     2022-02-03\n",
       "         ...    \n",
       "825   2017-12-15\n",
       "826   2020-07-02\n",
       "827   2022-07-08\n",
       "828          NaT\n",
       "829          NaT\n",
       "Name: Publication Date, Length: 830, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the \"Publisher\" column by the first opening parenthesis\n",
    "df[['Publisher', 'Publication Date']] = df['publisher'].str.split('(', 1, expand=True)\n",
    "\n",
    "# Extract the date and remove the closing parenthesis\n",
    "df['Publication Date'] = df['Publication Date'].str.rstrip(')')\n",
    "\n",
    "# convert Publication Date column to datetime format\n",
    "df['Publication Date'] = pd.to_datetime(df['Publication Date'], errors='coerce')\n",
    "\n",
    "df['Publication Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b12a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace null values in publisher with 'No Name'\n",
    "df['Publisher'].fillna('No Name', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62456e7",
   "metadata": {},
   "source": [
    "### 9. Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3684cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ISBN_13', 'link', 'complete_link', 'publisher', 'dimensions', 'all_prices'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95901c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Robust Python: Write Clean and Maintainable Code</td>\n",
       "      <td>Patrick Viafore</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 1st edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Time Series: A Data Analysis Approach Using R ...</td>\n",
       "      <td>No Name</td>\n",
       "      <td>English</td>\n",
       "      <td>Chapman and Hall/CRC; 1st edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Data Analysis For Business Decisions 2E: A Lab...</td>\n",
       "      <td>Andres Fortino PhD</td>\n",
       "      <td>English</td>\n",
       "      <td>Mercury Learning and Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Deep Learning from Scratch: Building with Pyth...</td>\n",
       "      <td>Seth Weidman</td>\n",
       "      <td>English</td>\n",
       "      <td>O'Reilly Media; 1st edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Python for Data Science: Comprehensive Guide t...</td>\n",
       "      <td>Alex Campbell</td>\n",
       "      <td>English</td>\n",
       "      <td>Independently published</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title              author  \\\n",
       "39    Robust Python: Write Clean and Maintainable Code     Patrick Viafore   \n",
       "75   Time Series: A Data Analysis Approach Using R ...             No Name   \n",
       "185  Data Analysis For Business Decisions 2E: A Lab...  Andres Fortino PhD   \n",
       "463  Deep Learning from Scratch: Building with Pyth...        Seth Weidman   \n",
       "760  Python for Data Science: Comprehensive Guide t...       Alex Campbell   \n",
       "\n",
       "    language                           Publisher  \n",
       "39   English        O'Reilly Media; 1st edition   \n",
       "75   English  Chapman and Hall/CRC; 1st edition   \n",
       "185  English   Mercury Learning and Information   \n",
       "463  English        O'Reilly Media; 1st edition   \n",
       "760  English            Independently published   "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_var = df.select_dtypes(object).sample(5)\n",
    "obj_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e96afb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 0\n",
       "author                0\n",
       "price               108\n",
       "pages                 0\n",
       "avg_reviews         128\n",
       "n_reviews             0\n",
       "star5                 0\n",
       "star4                 0\n",
       "star3                 0\n",
       "star2                 0\n",
       "star1                 0\n",
       "weight                0\n",
       "language             71\n",
       "average_value         0\n",
       "dimensions(cm)        0\n",
       "Publisher             0\n",
       "Publication Date    119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4629dc",
   "metadata": {},
   "source": [
    "### 10. Replace Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70e410fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing values appropriately\n",
    "df['avg_reviews'].fillna(df['avg_reviews'].mean(), inplace = True)\n",
    "df['price'].fillna('0', inplace = True)\n",
    "df['language'].fillna('No Language', inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
